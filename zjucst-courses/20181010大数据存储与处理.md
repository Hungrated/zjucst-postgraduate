20181010大数据存储与处理

MapReduce原理和开发
为什么用MapReduce
1 将计算移动到数据
2 分而治之（Divide and Conquer）
    Input->Splitting->Mapping->Shuffling->Reducing->Final result
    Split和Map可以放在同一节点执行；Shuffle和Reduce可以放在同一节点执行
    HDFS已经做了Split操作，只需将程序传输到各结点，再将计算结果合并即可

MapReduce特性
自动实现分布式并行计算
容错
提供状态监控工具
模型抽象简洁，程序员易用

Map/Reduce框架原理
一个Map/Reduce 作业（job）通常会把输入的数据集切分为若干独立的数据块，由map任务（task）以完全并行的方式执行数据处理过程。
框架会对map的输出先进行排序，然后把结果输入给reduce任务。通常作业的输入和输出都会被存储在文件系统（HDFS），不会丢失。

程序员关注的部分：Map业务逻辑与Reduce业务逻辑

Map/Reduce计算模型：核心是map和reduce两个函数，这两个函数由用户负责实现，功能是按一定的映射规则将输入的<key, value>对转换成另一个或一批<key, value>对输出

MapReduce执行流程（v1）
开始->向JobTracker申请JobId->检查Job的输出配置->切分Job的输入数据->生成job.xml->向JobTracker提交Job

执行Job启用Child JVM原因：
1 若不新建JVM，而在原JVM执行，代码有可能会控制TaskTracker
2 若代码导致TaskTracker挂掉，则整个节点都挂掉了，而在子JVM中则不影响原TaskTracker

JobTracker失败故障
1 JobTracker失败在所有的失败中是最严重的一种
2 hadoop没有处理jobtracker失败的机制。--它是一个单点故障
3 在未来的新版本中可能可以运行多个JobTracker
4 可以使用ZooKeeper来协作JobTracker（多Job）

MapReduce执行流程（v2）
引入Resource Manager/Node Manager，将结点运行情况和作业执行情况分开处理
1 用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等。
2 ResourceManager为该应用程序分配第一个Container，并与对应的NodeManager通信，要求它在这个Container中启动应用程序的ApplicationMaster。
3 ApplicationMaster首先向ResourceManager注册，这样，用户可以直接通过ResourceManager查看应用程序的运行状态，然后，它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7。
4 ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源。
5 一旦ApplicationMaster申请到资源后，则与对应的NodeManager通信，要求其启动任务。
6 NodeManager为任务设置好运行环境（包括环境变量、jar包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务。
7 各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。在应用程序运行过程中，用户可随时通过RPC向ApplicationMaster查询应用程序的当前运行状态。
8 应用程序运行完成后，ApplicationMaster向ResourceManager注销，并关闭自己。

大数据岗位分为四种：
做 基于Hadoop进行修改来满足业务需求 需要了解体系架构
用 把业务场景实现为MapReduce代码
运维 维护企业中运行Hadoop平台 需要了解体系架构
读数据 了解SQL语句 分析数据

MapReduce核心组件
InputFormat：输入文件 定义了数据文件如何分割和读取
InputSplit：输入文件拆分成多个块 定义了输入到单个Map任务的输入数据
RecordReader：对Record进行读取 实际上定义了如何将数据记录转化为一个(key,value)对的详细方法，并将数据记录传给Mapper类
Mapper：对Record进行解析 每一个Mapper类的实例生成了一个Java进程，负责处理某一个InputSplit上的数据
Combiner：合并相同key的键值对，减少partitioner数据通信开销
Partitioner：对数据进行分组 在Map工作完成之后，每一个Map函数会将结果传到对应的Reducer所在的节点，此时，用户可以提供一个Partitioner类，用来决定一个给定的(key,value)对传给哪个节点
Shuffle & Sort：对数据进行处理 传输到每一个Reducer节点上的、将被所有的Reduce函数接收到的Key,value对会被Hadoop自动排序（即Map生成的结果传送到某一个节点的时候，会被自动排序）
Reducer：做用户定义的Reduce操作


Hadoop Job
Hadoop中所有MapReduce程序以Job形式提交给集群运行
一个MapReduce Job被划分为若干个Map Task和Reduce Task并行执行
一个Job的提交包括数据和程序（jar文件）的提交

特点：Fault-tolerant 容错，很重要！
M/R Failures
Task fails
Try again?
Try again somewhere else?
Report failure
只有当map处理全部结束后，reduce过程才能够开始
Map需要考虑数据局部性，Reduce无需考虑数据局部性

理解Shuffle那张图

Hadoop平台应用特点
多种应用共用一个Hadoop平台
    生产性应用：数据加载，统计值计算，垃圾数据分析等
    批作业：机器学习等
    交互式作业：SQL查询、样本采集等

不同应用对硬件资源要求不同
    I/O密集型作业，如：机器学习算法
    CPU密集型作业：如：过滤，统计值计算，正则匹配等

作业之间存在依赖关系

如何提高Hadoop平台资源利用效率？作业合理调度、监控


MapReduce应用

日志分析 排序 搜索 搜索引擎 创建索引 广告计算
搜索关键字进行内容分类
计数 统计值计算 统计数据 过滤 分析 查询
垃圾数据分析 数据分析 机器学习 数据挖掘
大规模图像转换

YARN：资源管理系统

MR：离线计算框架
Storm：实时计算框架
Spark：内存计算框架
Giraph、GraphLib：图计算框架
Tez：DAG计算框架

ResourceManager
    处理客户端请求
    启动/监控ApplicationMaster
    监控NodeManager
    资源分配与调度
NodeManager
    单个节点上的资源管理
    处理来自ResourceManager的命令
    处理来自ApplicationMaster的命令
ApplicationMaster
    数据切分
    为应用程序申请资源，并分配给内部任务
    任务监控与容错

Yarn的调度策略

双层调度框架
RM将资源分配给AM
AM将资源进一步分配给各个Task
基于资源预留的调度策略
资源不够时，会为Task预留，直到资源充足
与“allornothing”策略不同（ApacheMesos）