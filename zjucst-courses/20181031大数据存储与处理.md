20181031大数据存储与处理

Spark

引入Spark原因：
1 Hadoop中只有一种计算模型MapReduce
2 Hadoop每次MR操作之后要进行多轮磁盘交互与网络传输

什么是Spark
一个集群计算平台：
快速（数据在内存中 不写磁盘）
通用性（提供了多样的数据处理方式 批处理 流处理 迭代的算法）
容易访问 提供fungus的库和API 支持多种编程语言
与其他大数据平台集成得非常好 尤其可以在Hadoop集群里运行

Spark核心：持久分布式数据集（RDD）

RDD是一个不可变的分布式对象集合

每个RDD被分成许多部分 它们可能在集群的不同结点上运算

RDD可以包含任意的Python Java Scala对象 或用户定义的类

创建RDD两种方法：
1 加载数据集 2 将分布式数据集转换成新的RDD
